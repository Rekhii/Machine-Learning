{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Heart Whisperer: A Machine Learning Adventure\n",
    "\n",
    "**Once upon a time, in a hospital far far away...**\n",
    "\n",
    "Doctors were drowning in patient data. ECGs piling up. Cholesterol numbers flying around like confetti. They needed a hero.\n",
    "\n",
    "Enter: **You. The Data Scientist.**\n",
    "\n",
    "Your mission? Build a model that can look at a patient's vitals and whisper: *\"This heart... needs attention.\"*\n",
    "\n",
    "Let's begin this adventure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Gathering the Troops (Imports)\n",
    "\n",
    "Every hero needs their tools. Batman has gadgets. We have... libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"Tools loaded. Let's save some hearts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Meeting Our Patients (Loading Data)\n",
    "\n",
    "918 patients walked into our clinic. Each one carrying secrets in their blood pressure, cholesterol, and heartbeats.\n",
    "\n",
    "Let's meet them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "print(f\"Patients in waiting room: {len(df)}\")\n",
    "print(f\"Vital signs recorded: {df.shape[1]}\")\n",
    "print(\"\\nFirst 5 patients walk in...\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What information do we have on each patient?\")\n",
    "print(\"=\"*50)\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}: {df[col].dtype}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nMissing values? {df.isnull().sum().sum()} (phew!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: The Plot Thickens (EDA)\n",
    "\n",
    "Before we build our heart-whispering model, we need to understand our patients.\n",
    "\n",
    "**The big question:** How many hearts are in danger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# The verdict\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "labels = ['Healthy Heart', 'Heart Disease']\n",
    "counts = df['HeartDisease'].value_counts().sort_index()\n",
    "\n",
    "# Pie chart - the dramatic reveal\n",
    "axes[0].pie(counts, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "            explode=(0, 0.05), shadow=True, startangle=90)\n",
    "axes[0].set_title('The Diagnosis Distribution\\n(Our Challenge)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart - the numbers\n",
    "bars = axes[1].bar(labels, counts, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[1].set_ylabel('Number of Patients', fontsize=12)\n",
    "axes[1].set_title('How Many Need Our Help?', fontsize=14, fontweight='bold')\n",
    "for bar, count in zip(bars, counts):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "                 str(count), ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{counts[1]} patients need us. Let's not let them down.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age: Does Getting Older Mean More Risk?\n",
    "\n",
    "Spoiler alert: Your heart has opinions about your birthday candles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Age distribution by heart disease\n",
    "for i, label in enumerate(labels):\n",
    "    subset = df[df['HeartDisease'] == i]['Age']\n",
    "    ax.hist(subset, bins=20, alpha=0.7, label=label, color=colors[i], edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Number of Patients', fontsize=12)\n",
    "ax.set_title('Age Distribution: When Do Hearts Start Complaining?', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.axvline(df[df['HeartDisease']==1]['Age'].mean(), color='#e74c3c', linestyle='--', \n",
    "           label=f'Mean Age (Disease): {df[df[\"HeartDisease\"]==1][\"Age\"].mean():.1f}')\n",
    "ax.axvline(df[df['HeartDisease']==0]['Age'].mean(), color='#2ecc71', linestyle='--',\n",
    "           label=f'Mean Age (Healthy): {df[df[\"HeartDisease\"]==0][\"Age\"].mean():.1f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage age of healthy hearts: {df[df['HeartDisease']==0]['Age'].mean():.1f} years\")\n",
    "print(f\"Average age of troubled hearts: {df[df['HeartDisease']==1]['Age'].mean():.1f} years\")\n",
    "print(\"\\nLesson: Age is just a number... that your heart takes VERY seriously.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chest Pain Mystery\n",
    "\n",
    "Not all chest pain is created equal. Let's decode the types:\n",
    "- **ASY**: Asymptomatic (the silent danger)\n",
    "- **ATA**: Atypical Angina  \n",
    "- **NAP**: Non-Anginal Pain\n",
    "- **TA**: Typical Angina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "chest_pain_crosstab = pd.crosstab(df['ChestPainType'], df['HeartDisease'])\n",
    "chest_pain_crosstab.columns = labels\n",
    "chest_pain_crosstab.plot(kind='bar', ax=ax, color=colors, edgecolor='black', width=0.8)\n",
    "\n",
    "ax.set_xlabel('Chest Pain Type', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('The Chest Pain Plot Twist\\n(ASY = The Silent Killer)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Diagnosis')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot twist: ASY (Asymptomatic) patients have the HIGHEST heart disease rate!\")\n",
    "print(\"Sometimes the quietest chest is hiding the loudest problem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Stats Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numerical Features - Quick Health Check:\")\n",
    "print(\"=\"*60)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Preparing for Battle (Data Preprocessing)\n",
    "\n",
    "Our model can't read text. It only speaks numbers. Time for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy - never mess with the original evidence\n",
    "df_model = df.copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {cat_cols}\")\n",
    "\n",
    "# Label encoding for categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df_model[col] = le.fit_transform(df_model[col])\n",
    "    print(f\"  {col} encoded\")\n",
    "\n",
    "print(\"\\nTranslation complete. Model can now understand.\")\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_model.drop('HeartDisease', axis=1)\n",
    "y = df_model['HeartDisease']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeatures we're using to predict: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sacred split: training warriors vs testing judges\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training army size: {len(X_train)} patients\")\n",
    "print(f\"Testing jury size: {len(X_test)} patients\")\n",
    "print(f\"\\nTraining set disease ratio: {y_train.mean():.2%}\")\n",
    "print(f\"Testing set disease ratio: {y_test.mean():.2%}\")\n",
    "print(\"\\nPerfectly balanced, as all things should be. - Thanos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features - put everyone on equal footing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled. No more favoritism toward big numbers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: The Tournament of Models\n",
    "\n",
    "Three champions enter the arena. Only one will become THE HEART WHISPERER.\n",
    "\n",
    "**The Contenders:**\n",
    "1. **Logistic Regression** - The wise elder, simple but reliable\n",
    "2. **Random Forest** - The army of decision trees\n",
    "3. **Gradient Boosting** - The perfectionist who learns from mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our contenders\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"LET THE TOURNAMENT BEGIN!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name} enters the arena...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    if name == 'Random Forest' or name == 'Gradient Boosting':\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nResults for {name}:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tournament Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [r['accuracy'] for r in results.values()],\n",
    "    'Precision': [r['precision'] for r in results.values()],\n",
    "    'Recall': [r['recall'] for r in results.values()],\n",
    "    'F1 Score': [r['f1'] for r in results.values()],\n",
    "    'AUC-ROC': [r['auc'] for r in results.values()]\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nTOURNAMENT SCOREBOARD\")\n",
    "print(\"=\"*70)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(summary_df))\n",
    "width = 0.15\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
    "colors_metrics = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    bars = ax.bar(x + i*width, summary_df[metric], width, label=metric, color=colors_metrics[i])\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('The Tournament Results\\n(Who Will Be Crowned?)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 2)\n",
    "ax.set_xticklabels(summary_df['Model'])\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0.7, 1.0)\n",
    "ax.axhline(y=0.9, color='gray', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Declare winner\n",
    "winner = summary_df.loc[summary_df['F1 Score'].idxmax(), 'Model']\n",
    "print(f\"\\nAND THE WINNER IS... {winner.upper()}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6: The Perfect Confusion Matrix\n",
    "\n",
    "This is it. The moment of truth. The confusion matrix tells us:\n",
    "- **True Positives (TP):** We said disease, it WAS disease (saved a life)\n",
    "- **True Negatives (TN):** We said healthy, it WAS healthy (no false alarm)\n",
    "- **False Positives (FP):** We said disease, but they were fine (unnecessary panic)\n",
    "- **False Negatives (FN):** We said healthy, but they had disease (THE WORST MISTAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perfect_confusion_matrix(y_true, y_pred, model_name, ax=None):\n",
    "    \"\"\"\n",
    "    Creates a beautiful, informative confusion matrix visualization.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum() * 100\n",
    "    \n",
    "    # Create custom annotations\n",
    "    labels = np.array([\n",
    "        [f'TN\\n{cm[0,0]}\\n({cm_percent[0,0]:.1f}%)', f'FP\\n{cm[0,1]}\\n({cm_percent[0,1]:.1f}%)'],\n",
    "        [f'FN\\n{cm[1,0]}\\n({cm_percent[1,0]:.1f}%)', f'TP\\n{cm[1,1]}\\n({cm_percent[1,1]:.1f}%)']\n",
    "    ])\n",
    "    \n",
    "    # Custom colormap: green for correct, red for errors\n",
    "    colors_cm = np.array([\n",
    "        ['#2ecc71', '#e74c3c'],  # TN (green), FP (red)\n",
    "        ['#e74c3c', '#2ecc71']   # FN (red), TP (green)\n",
    "    ])\n",
    "    \n",
    "    # Plot\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.add_patch(plt.Rectangle((j, 1-i), 1, 1, fill=True, \n",
    "                                        color=colors_cm[i, j], alpha=0.7))\n",
    "            ax.text(j + 0.5, 1.5 - i, labels[i, j], \n",
    "                    ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "                    color='white' if cm[i,j] > cm.max()/3 else 'black')\n",
    "    \n",
    "    ax.set_xlim(0, 2)\n",
    "    ax.set_ylim(0, 2)\n",
    "    ax.set_xticks([0.5, 1.5])\n",
    "    ax.set_yticks([0.5, 1.5])\n",
    "    ax.set_xticklabels(['Healthy', 'Disease'], fontsize=12)\n",
    "    ax.set_yticklabels(['Disease', 'Healthy'], fontsize=12)\n",
    "    ax.set_xlabel('Predicted', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Actual', fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add border\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for ax, (name, res) in zip(axes, results.items()):\n",
    "    plot_perfect_confusion_matrix(y_test, res['y_pred'], name, ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices_all.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGreen = Correct predictions (what we want)\")\n",
    "print(\"Red = Errors (what we want to minimize)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ULTIMATE Confusion Matrix (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model based on F1 score\n",
    "best_model_name = summary_df.loc[summary_df['F1 Score'].idxmax(), 'Model']\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "cm = plot_perfect_confusion_matrix(y_test, best_results['y_pred'], \n",
    "                                    f'{best_model_name} (THE CHAMPION)', ax)\n",
    "\n",
    "# Add summary stats below\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "summary_text = f\"\"\"\n",
    "True Negatives: {tn} healthy patients correctly identified\n",
    "True Positives: {tp} disease patients correctly identified \n",
    "False Positives: {fp} false alarms (said disease, was healthy)\n",
    "False Negatives: {fn} missed diagnoses (said healthy, had disease)\n",
    "\n",
    "Total Correct: {tn + tp} / {len(y_test)} = {(tn + tp) / len(y_test) * 100:.1f}%\n",
    "\"\"\"\n",
    "\n",
    "plt.figtext(0.5, -0.05, summary_text, ha='center', fontsize=11, \n",
    "            fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('best_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn Style Confusion Matrix (Alternative View)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (name, res) in zip(axes, results.items()):\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    \n",
    "    # Seaborn heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Healthy', 'Disease'],\n",
    "                yticklabels=['Healthy', 'Disease'],\n",
    "                ax=ax, annot_kws={'size': 20}, cbar=False)\n",
    "    \n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('Actual', fontsize=12)\n",
    "    ax.set_title(f'{name}\\nAccuracy: {res[\"accuracy\"]*100:.1f}%', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: ROC Curves - The Performance Art\n",
    "\n",
    "ROC (Receiver Operating Characteristic) curve shows us how well our model distinguishes between classes.\n",
    "\n",
    "The closer to the top-left corner, the better. AUC = 1.0 means perfect. AUC = 0.5 means random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_roc = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for (name, res), color in zip(results.items(), colors_roc):\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_pred_proba'])\n",
    "    ax.plot(fpr, tpr, color=color, linewidth=2, \n",
    "            label=f'{name} (AUC = {res[\"auc\"]:.3f})')\n",
    "\n",
    "# Diagonal line (random guessing)\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Guess (AUC = 0.500)')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves: The Battle of Discrimination\\n(Higher = Better)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Shade the area under the best curve\n",
    "best_fpr, best_tpr, _ = roc_curve(y_test, best_results['y_pred_proba'])\n",
    "ax.fill_between(best_fpr, best_tpr, alpha=0.1, color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Feature Importance - What Matters Most?\n",
    "\n",
    "What signs should doctors look for? Let's ask our champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest (it has this attribute)\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_importance = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(feature_importance)))\n",
    "bars = ax.barh(feature_importance['feature'], feature_importance['importance'], \n",
    "               color=colors_importance, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Importance Score', fontsize=12)\n",
    "ax.set_title('What Makes a Heart Troubled?\\n(Feature Importance from Random Forest)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, feature_importance['importance']):\n",
    "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.3f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTOP 3 WARNING SIGNS:\")\n",
    "print(\"=\"*40)\n",
    "for i, row in feature_importance.tail(3).iloc[::-1].iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9: Classification Report - The Full Medical Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL MEDICAL REPORT: {best_model_name.upper()}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "print(classification_report(y_test, best_results['y_pred'], \n",
    "                           target_names=['Healthy', 'Heart Disease']))\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Precision (Disease): When we say 'disease', we're right {results[best_model_name]['precision']*100:.1f}% of the time\")\n",
    "print(f\"Recall (Disease): We catch {results[best_model_name]['recall']*100:.1f}% of actual disease cases\")\n",
    "print(f\"F1 Score: Balanced performance of {results[best_model_name]['f1']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue: The Heart Whisperer Lives\n",
    "\n",
    "Our journey is complete. We built a model that can look at a patient's vitals and predict heart disease with impressive accuracy.\n",
    "\n",
    "**What we learned:**\n",
    "1. Age matters, but so do many other factors\n",
    "2. Asymptomatic chest pain (no symptoms) is actually the most dangerous sign\n",
    "3. Machine learning can be a powerful tool in healthcare\n",
    "4. But always remember: this model assists doctors, it doesn't replace them\n",
    "\n",
    "**The End.**\n",
    "\n",
    "*...or is it just the beginning?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "      _____\n",
    "     /     \\\\\n",
    "    /       \\\\\n",
    "   |  HEART  |\n",
    "   |  SAVED  |\n",
    "    \\\\       /\n",
    "     \\\\_____/\n",
    "        |\n",
    "        |\n",
    "    ____|____\n",
    "   |         |\n",
    "   |  MODEL  |\n",
    "   |  READY  |\n",
    "   |_________|\n",
    "\n",
    "Thank you for joining this adventure!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
